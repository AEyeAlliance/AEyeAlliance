{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to measure run-time\n",
    "import time\n",
    "\n",
    "# to shuffle data\n",
    "import random\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# for csv dataset\n",
    "import torchvision\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd \n",
    "from urllib import request\n",
    "import requests\n",
    "\n",
    "# import statements for iterating over csv file\n",
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "# to get the alphabet\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload and read the csv files from the github repo\n",
    "# change once get more data\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/HelenG123/aeye-alliance/master/Labelled%20Data/symbols_letters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'b': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'c': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'd': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'e': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'f': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'g': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'h': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'i': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'j': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'k': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'l': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'm': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'n': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'o': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'p': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'q': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'r': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 's': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 't': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'u': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'v': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'w': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'x': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'y': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'z': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ' ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '#': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], '.': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], ',': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], ':': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], \"'\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], '-': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], ';': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], '?': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], '!': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'C': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "# generate the targets \n",
    "# the targets are one hot encoding vectors\n",
    "\n",
    "alphabet = list(string.ascii_lowercase)\n",
    "target = {}\n",
    "\n",
    "# Initalize a target dict that has letters as its keys and empty one-hot encoding vectors of size 37 as its values\n",
    "for letter in alphabet: \n",
    "    target[letter] = [0] * 37\n",
    "\n",
    "# Do the one-hot encoding for each letter now \n",
    "curr_pos = 0 \n",
    "for curr_letter in target.keys():\n",
    "    target[curr_letter][curr_pos] = 1\n",
    "    curr_pos += 1  \n",
    "\n",
    "# extra symbols \n",
    "symbols = [' ', '#', '.', ',', ':', '\\'', '-', ';', '?', '!', 'C'] # C stands for CAPS\n",
    "\n",
    "# create vectors\n",
    "for curr_symbol in symbols:\n",
    "    target[curr_symbol] = [0] * 37\n",
    "\n",
    "# create one-hot encoding vectors\n",
    "for curr_symbol in symbols:\n",
    "    target[curr_symbol][curr_pos] = 1\n",
    "    curr_pos += 1\n",
    "\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all data from the csv file\n",
    "data=[]\n",
    "\n",
    "# iterate over csv file\n",
    "for i, row in df.iterrows():\n",
    "    # store the image and label\n",
    "    picture = []\n",
    "    url = row['Labeled Data']\n",
    "    label = row['Label']\n",
    "    curr_target = target[label[11]]\n",
    "    x = urllib.request.urlopen(url)\n",
    "    resp = x.read()\n",
    "    image = np.array(bytearray(resp), dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    # resize image to 28x28x3\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "    # normalize to 0-1\n",
    "    image = image.astype(np.float32)/255.0\n",
    "    image = torch.from_numpy(image)\n",
    "    picture.append(image)\n",
    "    # convert the target to a long tensor\n",
    "    curr_target=torch.LongTensor([curr_target])\n",
    "    picture.append(curr_target)\n",
    "    # append the current image & target\n",
    "    data.append(picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: ' ', 27: '#', 28: '.', 29: ',', 30: ':', 31: \"'\", 32: '-', 33: ';', 34: '?', 35: '!', 36: 'C'}\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary of all the characters \n",
    "characters = alphabet + symbols\n",
    "\n",
    "index2char = {}\n",
    "number = 0\n",
    "for char in characters: \n",
    "    index2char[number] = char\n",
    "    number += 1\n",
    "\n",
    "print(index2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of each character in a dataset\n",
    "def num_chars(dataset, index2char):\n",
    "    chars = {}\n",
    "    for _, label in dataset:\n",
    "        char = index2char[int(torch.argmax(label))]\n",
    "        # update\n",
    "        if char in chars:\n",
    "            chars[char] += 1\n",
    "        # initialize\n",
    "        else:\n",
    "            chars[char] = 1\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'\": 52, ':': 58, ',': 51, '!': 50, '#': 83, '.': 52, '?': 55, ';': 58, '-': 54, 'a': 203, 'b': 188, 'c': 201, 'd': 68, 'e': 83, 'f': 57, 'g': 58, 'h': 75, 'i': 64, 'k': 53, 'l': 67, 'm': 59, 'n': 63, 'o': 69, 'p': 57, 'q': 51, 'r': 65, 's': 59, 't': 79, 'u': 65, 'v': 50, 'w': 58, 'x': 53, 'z': 52, 'j': 50, 'y': 59, ' ': 15, 'C': 67}\n"
     ]
    }
   ],
   "source": [
    "print(num_chars(data, index2char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "87\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "# Create dataloader objects\n",
    "\n",
    "# shuffle all the data\n",
    "random.shuffle(data)\n",
    "\n",
    "# batch sizes for train, test, and validation\n",
    "batch_size_train = 10\n",
    "batch_size_test = 3\n",
    "batch_size_validation = 3\n",
    "\n",
    "# 2601\n",
    "# splitting data to get training, test, and validation sets\n",
    "# change once get more data\n",
    "# 2080 for train\n",
    "train_dataset = data[:2080] #data[:1750]#\n",
    "# test has 260\n",
    "test_dataset = data[2080:2340] #data[1750:2000]#\n",
    "# validation has 260\n",
    "validation_dataset = data[2340:] #data[2000:]#\n",
    "\n",
    "# create the dataloader objects\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size_test, shuffle=False)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=batch_size_validation, shuffle=True)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))\n",
    "print(len(validation_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "{'c': 16, 'C': 4, 'd': 11, '#': 12, 'b': 22, 'g': 6, 'k': 7, 'z': 8, 'r': 6, 'f': 10, 'h': 11, 'n': 10, 't': 8, 'l': 6, 'x': 5, 'a': 18, 'o': 3, 's': 2, 'u': 6, 'i': 7, ',': 5, '-': 5, 'e': 9, 'y': 3, 'v': 8, ';': 5, ':': 3, 'q': 4, 'p': 7, \"'\": 8, 'w': 3, '?': 3, '!': 2, '.': 3, 'm': 3, ' ': 1}\n"
     ]
    }
   ],
   "source": [
    "print(len(num_chars(test_dataset, index2char)))\n",
    "print(num_chars(test_dataset, index2char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "# to check if a dataset is missing a char\n",
    "test_chars = num_chars(test_dataset, index2char)\n",
    "\n",
    "num = 0\n",
    "for char in characters:\n",
    "    if char in test_chars:\n",
    "        num += 1\n",
    "    else:\n",
    "        break\n",
    "print(num) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Linear(in_features=1568, out_features=100, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=100, out_features=37, bias=True)\n",
      "  )\n",
      ")\n",
      "# parameter:  174685\n"
     ]
    }
   ],
   "source": [
    "# defines the convolutional neural network\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            #3x28x28\n",
    "            nn.Conv2d(in_channels=3, \n",
    "                      out_channels=16, \n",
    "                      kernel_size=5,\n",
    "                      stride=1, \n",
    "                      padding=2),\n",
    "            # batch normalization\n",
    "            # nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True), \n",
    "            #16x28x28\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            #16x14x14\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        #16x14x14\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, \n",
    "                      out_channels=32, \n",
    "                      kernel_size=5,\n",
    "                      stride=1, \n",
    "                      padding=2),\n",
    "            # batch normalization\n",
    "            # nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True), \n",
    "            #32x14x14\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            #32x7x7\n",
    "            nn.LeakyReLU()\n",
    "        ) \n",
    "        # linearly \n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Linear(32*7*7, 100),\n",
    "            # batch normalization\n",
    "            # nn.BatchNorm1d(100),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(100, 37)\n",
    "        )\n",
    "        #1x37\n",
    "    \n",
    "    def forward(self, x): \n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        # flatten the dataset\n",
    "        out = out.view(-1, 32*7*7)\n",
    "        out = self.block3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# convolutional neural network model\n",
    "model = CNN()\n",
    "\n",
    "# print summary of the neural network model to check if everything is fine. \n",
    "print(model)\n",
    "print(\"# parameter: \", sum([param.nelement() for param in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the learning rate\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Using a variable to store the cross entropy method\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Using a variable to store the optimizer \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get which characters were missclassified\n",
    "def get_chars(indices, incorrect_dict, index2char):\n",
    "    for i in indices:\n",
    "        char = index2char[i]\n",
    "        # update\n",
    "        if char in incorrect_dict:\n",
    "            incorrect_dict[char] += 1\n",
    "    return incorrect_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tingyisu/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 3.5398\n",
      "Validation Loss: 3.5730\n",
      "Accuracy on the test set: 8.8462%\n",
      "Number of missclassifid characters: {'a': 25, 'b': 13, 'c': 1, 'd': 8, 'e': 8, 'f': 9, 'g': 6, 'h': 4, 'i': 5, 'j': 2, 'k': 4, 'l': 6, 'm': 9, 'n': 7, 'o': 4, 'p': 4, 'q': 8, 'r': 4, 's': 9, 't': 8, 'u': 13, 'v': 3, 'w': 6, 'x': 8, 'y': 5, 'z': 4, ' ': 0, '#': 4, '.': 4, ',': 8, ':': 4, \"'\": 4, '-': 5, ';': 6, '?': 6, '!': 8, 'C': 5}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tingyisu/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:81: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Training Loss: 3.5074\n",
      "Validation Loss: 3.5386\n",
      "Accuracy on the test set: 9.2308%\n",
      "Number of missclassifid characters: {'a': 25, 'b': 13, 'c': 0, 'd': 8, 'e': 8, 'f': 9, 'g': 6, 'h': 4, 'i': 5, 'j': 2, 'k': 4, 'l': 6, 'm': 9, 'n': 7, 'o': 4, 'p': 4, 'q': 8, 'r': 4, 's': 9, 't': 8, 'u': 13, 'v': 3, 'w': 6, 'x': 8, 'y': 5, 'z': 4, ' ': 0, '#': 4, '.': 4, ',': 8, ':': 4, \"'\": 4, '-': 5, ';': 6, '?': 6, '!': 8, 'C': 5}\n",
      "\n",
      "Epoch: 3\n",
      "Training Loss: 3.3106\n",
      "Validation Loss: 2.9586\n",
      "Accuracy on the test set: 24.6154%\n",
      "Number of missclassifid characters: {'a': 3, 'b': 0, 'c': 7, 'd': 8, 'e': 7, 'f': 9, 'g': 6, 'h': 4, 'i': 5, 'j': 2, 'k': 4, 'l': 6, 'm': 9, 'n': 7, 'o': 3, 'p': 3, 'q': 8, 'r': 4, 's': 9, 't': 8, 'u': 13, 'v': 2, 'w': 3, 'x': 8, 'y': 4, 'z': 4, ' ': 0, '#': 0, '.': 4, ',': 8, ':': 4, \"'\": 4, '-': 5, ';': 6, '?': 6, '!': 8, 'C': 5}\n",
      "\n",
      "Epoch: 4\n",
      "Training Loss: 2.0776\n",
      "Validation Loss: 1.4996\n",
      "Accuracy on the test set: 70.0000%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 1, 'd': 6, 'e': 0, 'f': 3, 'g': 2, 'h': 0, 'i': 0, 'j': 0, 'k': 1, 'l': 3, 'm': 2, 'n': 4, 'o': 0, 'p': 3, 'q': 5, 'r': 1, 's': 1, 't': 0, 'u': 2, 'v': 1, 'w': 1, 'x': 8, 'y': 5, 'z': 1, ' ': 0, '#': 0, '.': 2, ',': 8, ':': 0, \"'\": 0, '-': 1, ';': 3, '?': 6, '!': 7, 'C': 1}\n",
      "\n",
      "Epoch: 5\n",
      "Training Loss: 0.9670\n",
      "Validation Loss: 0.8633\n",
      "Accuracy on the test set: 81.5385%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 3, 'd': 2, 'e': 0, 'f': 1, 'g': 1, 'h': 0, 'i': 1, 'j': 0, 'k': 0, 'l': 1, 'm': 2, 'n': 2, 'o': 0, 'p': 1, 'q': 3, 'r': 1, 's': 1, 't': 0, 'u': 1, 'v': 2, 'w': 2, 'x': 3, 'y': 4, 'z': 1, ' ': 0, '#': 0, '.': 1, ',': 5, ':': 0, \"'\": 0, '-': 1, ';': 3, '?': 1, '!': 4, 'C': 1}\n",
      "\n",
      "Epoch: 6\n",
      "Training Loss: 0.5855\n",
      "Validation Loss: 0.7397\n",
      "Accuracy on the test set: 87.3077%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 2, 'd': 1, 'e': 0, 'f': 1, 'g': 2, 'h': 0, 'i': 1, 'j': 0, 'k': 0, 'l': 1, 'm': 2, 'n': 2, 'o': 0, 'p': 1, 'q': 3, 'r': 1, 's': 1, 't': 0, 'u': 0, 'v': 2, 'w': 1, 'x': 3, 'y': 3, 'z': 1, ' ': 0, '#': 0, '.': 1, ',': 0, ':': 0, \"'\": 0, '-': 0, ';': 0, '?': 1, '!': 3, 'C': 0}\n",
      "\n",
      "Epoch: 7\n",
      "Training Loss: 0.4407\n",
      "Validation Loss: 0.5156\n",
      "Accuracy on the test set: 90.3846%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 2, 'd': 0, 'e': 0, 'f': 2, 'g': 2, 'h': 0, 'i': 0, 'j': 0, 'k': 0, 'l': 1, 'm': 2, 'n': 2, 'o': 0, 'p': 1, 'q': 1, 'r': 0, 's': 1, 't': 0, 'u': 0, 'v': 1, 'w': 2, 'x': 3, 'y': 2, 'z': 1, ' ': 0, '#': 0, '.': 1, ',': 0, ':': 0, \"'\": 0, '-': 0, ';': 0, '?': 0, '!': 0, 'C': 1}\n",
      "\n",
      "Epoch: 8\n",
      "Training Loss: 0.3489\n",
      "Validation Loss: 0.4349\n",
      "Accuracy on the test set: 92.3077%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 1, 'd': 0, 'e': 0, 'f': 0, 'g': 1, 'h': 0, 'i': 0, 'j': 0, 'k': 0, 'l': 1, 'm': 2, 'n': 1, 'o': 0, 'p': 1, 'q': 2, 'r': 0, 's': 1, 't': 0, 'u': 0, 'v': 1, 'w': 2, 'x': 4, 'y': 1, 'z': 0, ' ': 0, '#': 0, '.': 0, ',': 0, ':': 0, \"'\": 0, '-': 0, ';': 1, '?': 0, '!': 0, 'C': 1}\n",
      "\n",
      "Epoch: 9\n",
      "Training Loss: 0.3029\n",
      "Validation Loss: 0.4058\n",
      "Accuracy on the test set: 91.1538%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 1, 'd': 0, 'e': 1, 'f': 1, 'g': 1, 'h': 0, 'i': 0, 'j': 0, 'k': 0, 'l': 1, 'm': 2, 'n': 1, 'o': 0, 'p': 1, 'q': 2, 'r': 0, 's': 1, 't': 0, 'u': 0, 'v': 1, 'w': 2, 'x': 3, 'y': 1, 'z': 1, ' ': 0, '#': 0, '.': 1, ',': 0, ':': 0, \"'\": 0, '-': 0, ';': 0, '?': 0, '!': 1, 'C': 1}\n",
      "\n",
      "Epoch: 10\n",
      "Training Loss: 0.2649\n",
      "Validation Loss: 0.4104\n",
      "Accuracy on the test set: 92.6923%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 1, 'f': 0, 'g': 1, 'h': 0, 'i': 0, 'j': 0, 'k': 0, 'l': 1, 'm': 2, 'n': 1, 'o': 0, 'p': 1, 'q': 2, 'r': 0, 's': 1, 't': 0, 'u': 0, 'v': 2, 'w': 2, 'x': 2, 'y': 1, 'z': 1, ' ': 0, '#': 0, '.': 0, ',': 0, ':': 0, \"'\": 0, '-': 0, ';': 0, '?': 0, '!': 0, 'C': 1}\n",
      "\n",
      "Epoch: 11\n",
      "Training Loss: 0.2323\n",
      "Validation Loss: 0.3713\n",
      "Accuracy on the test set: 92.3077%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 0, 'g': 1, 'h': 0, 'i': 1, 'j': 0, 'k': 0, 'l': 1, 'm': 2, 'n': 2, 'o': 0, 'p': 1, 'q': 0, 'r': 0, 's': 1, 't': 0, 'u': 0, 'v': 1, 'w': 2, 'x': 3, 'y': 1, 'z': 1, ' ': 0, '#': 0, '.': 0, ',': 0, ':': 0, \"'\": 0, '-': 0, ';': 1, '?': 0, '!': 1, 'C': 1}\n",
      "\n",
      "Epoch: 12\n",
      "Training Loss: 0.1962\n",
      "Validation Loss: 0.3499\n",
      "Accuracy on the test set: 93.8462%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 0, 'g': 1, 'h': 0, 'i': 0, 'j': 0, 'k': 0, 'l': 1, 'm': 2, 'n': 0, 'o': 0, 'p': 1, 'q': 2, 'r': 0, 's': 1, 't': 0, 'u': 0, 'v': 0, 'w': 2, 'x': 3, 'y': 0, 'z': 0, ' ': 0, '#': 0, '.': 0, ',': 0, ':': 0, \"'\": 0, '-': 0, ';': 1, '?': 0, '!': 1, 'C': 1}\n",
      "\n",
      "Epoch: 13\n",
      "Training Loss: 0.1837\n",
      "Validation Loss: 0.3452\n",
      "Accuracy on the test set: 93.4615%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 1, 'd': 0, 'e': 0, 'f': 0, 'g': 1, 'h': 0, 'i': 0, 'j': 0, 'k': 0, 'l': 1, 'm': 2, 'n': 0, 'o': 0, 'p': 1, 'q': 2, 'r': 0, 's': 0, 't': 0, 'u': 0, 'v': 1, 'w': 1, 'x': 4, 'y': 1, 'z': 0, ' ': 0, '#': 0, '.': 0, ',': 0, ':': 0, \"'\": 0, '-': 0, ';': 0, '?': 0, '!': 1, 'C': 1}\n",
      "\n",
      "Epoch: 14\n",
      "Training Loss: 0.1623\n",
      "Validation Loss: 0.3594\n",
      "Accuracy on the test set: 93.0769%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 1, 'g': 1, 'h': 0, 'i': 0, 'j': 0, 'k': 0, 'l': 2, 'm': 2, 'n': 1, 'o': 0, 'p': 1, 'q': 1, 'r': 0, 's': 1, 't': 0, 'u': 0, 'v': 1, 'w': 2, 'x': 3, 'y': 0, 'z': 0, ' ': 0, '#': 0, '.': 0, ',': 0, ':': 0, \"'\": 0, '-': 0, ';': 0, '?': 0, '!': 1, 'C': 1}\n",
      "\n",
      "Epoch: 15\n",
      "Training Loss: 0.1520\n",
      "Validation Loss: 0.3423\n",
      "Accuracy on the test set: 93.0769%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 0, 'g': 1, 'h': 0, 'i': 0, 'j': 0, 'k': 0, 'l': 0, 'm': 2, 'n': 2, 'o': 0, 'p': 1, 'q': 1, 'r': 0, 's': 0, 't': 0, 'u': 1, 'v': 0, 'w': 0, 'x': 6, 'y': 2, 'z': 0, ' ': 0, '#': 0, '.': 0, ',': 0, ':': 0, \"'\": 0, '-': 0, ';': 0, '?': 0, '!': 1, 'C': 1}\n",
      "\n",
      "Epoch: 16\n",
      "Training Loss: 0.1377\n",
      "Validation Loss: 0.3654\n",
      "Accuracy on the test set: 92.3077%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 1, 'd': 0, 'e': 0, 'f': 5, 'g': 1, 'h': 0, 'i': 0, 'j': 0, 'k': 0, 'l': 0, 'm': 2, 'n': 0, 'o': 0, 'p': 1, 'q': 0, 'r': 0, 's': 0, 't': 0, 'u': 0, 'v': 1, 'w': 2, 'x': 6, 'y': 0, 'z': 0, ' ': 0, '#': 0, '.': 0, ',': 0, ':': 0, \"'\": 0, '-': 0, ';': 0, '?': 0, '!': 0, 'C': 1}\n",
      "\n",
      "Epoch: 17\n",
      "Training Loss: 0.1436\n",
      "Validation Loss: 0.3761\n",
      "Accuracy on the test set: 93.0769%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 0, 'g': 1, 'h': 0, 'i': 0, 'j': 0, 'k': 0, 'l': 1, 'm': 2, 'n': 0, 'o': 0, 'p': 0, 'q': 2, 'r': 0, 's': 0, 't': 0, 'u': 0, 'v': 0, 'w': 0, 'x': 5, 'y': 2, 'z': 0, ' ': 0, '#': 0, '.': 1, ',': 0, ':': 0, \"'\": 1, '-': 0, ';': 1, '?': 0, '!': 1, 'C': 1}\n",
      "\n",
      "Epoch: 18\n",
      "Training Loss: 0.1310\n",
      "Validation Loss: 0.3809\n",
      "Accuracy on the test set: 93.8462%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 1, 'f': 0, 'g': 1, 'h': 0, 'i': 0, 'j': 0, 'k': 0, 'l': 0, 'm': 2, 'n': 1, 'o': 0, 'p': 0, 'q': 2, 'r': 0, 's': 0, 't': 0, 'u': 0, 'v': 2, 'w': 1, 'x': 3, 'y': 1, 'z': 0, ' ': 0, '#': 0, '.': 0, ',': 0, ':': 0, \"'\": 1, '-': 0, ';': 0, '?': 0, '!': 0, 'C': 1}\n",
      "\n",
      "Epoch: 19\n",
      "Training Loss: 0.1189\n",
      "Validation Loss: 0.3217\n",
      "Accuracy on the test set: 94.2308%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 1, 'g': 1, 'h': 0, 'i': 0, 'j': 0, 'k': 0, 'l': 1, 'm': 2, 'n': 0, 'o': 0, 'p': 0, 'q': 2, 'r': 0, 's': 0, 't': 0, 'u': 0, 'v': 0, 'w': 2, 'x': 4, 'y': 0, 'z': 1, ' ': 0, '#': 0, '.': 0, ',': 0, ':': 0, \"'\": 0, '-': 0, ';': 0, '?': 0, '!': 0, 'C': 1}\n",
      "\n",
      "Epoch: 20\n",
      "Training Loss: 0.1049\n",
      "Validation Loss: 0.3296\n",
      "Accuracy on the test set: 95.0000%\n",
      "Number of missclassifid characters: {'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 0, 'g': 1, 'h': 0, 'i': 1, 'j': 0, 'k': 0, 'l': 0, 'm': 2, 'n': 0, 'o': 0, 'p': 1, 'q': 1, 'r': 0, 's': 1, 't': 0, 'u': 0, 'v': 0, 'w': 1, 'x': 3, 'y': 0, 'z': 0, ' ': 0, '#': 0, '.': 0, ',': 0, ':': 0, \"'\": 0, '-': 0, ';': 0, '?': 0, '!': 1, 'C': 1}\n",
      "\n",
      "\n",
      "time: 30.416720151901245 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# list of all train_losses \n",
    "train_losses = []\n",
    "\n",
    "# list of all validation losses \n",
    "validation_losses = []\n",
    "\n",
    "# for loop that iterates over all the epochs\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # variables to store/keep track of the loss and number of iterations\n",
    "    train_loss = 0\n",
    "    num_iter_train = 0\n",
    "\n",
    "    # train the model\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over train_loader\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # need to permute so that the images are of size 3x28x28 \n",
    "        # essential to be able to feed images into the model\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Zero the gradient buffer\n",
    "        # resets the gradient after each epoch so that the gradients don't add up\n",
    "        optimizer.zero_grad()  \n",
    "\n",
    "        # Forward, get output\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # convert the labels from one hot encoding vectors into integer values \n",
    "        labels = labels.view(-1, 37)\n",
    "        y_true = torch.argmax(labels, 1)\n",
    "\n",
    "        # calculate training loss\n",
    "        loss = criterion(outputs, y_true)\n",
    "        \n",
    "        # Backward (computes all the gradients)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimize\n",
    "        # loops through all parameters and updates weights by using the gradients \n",
    "        # takes steps backwards to optimize (to reach the minimum weight)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update the validation and number of iterations\n",
    "        train_loss += loss.data[0]\n",
    "        num_iter_train += 1\n",
    "\n",
    "    print('Epoch: {}'.format(epoch+1))\n",
    "    print('Training Loss: {:.4f}'.format(train_loss/num_iter_train))\n",
    "    # append training loss over all the epochs\n",
    "    train_losses.append(train_loss/num_iter_train)\n",
    "\n",
    "    # evaluate the model\n",
    "    model.eval()\n",
    "    \n",
    "    # variables to store/keep track of the loss and number of iterations\n",
    "    validation_loss = 0\n",
    "    num_iter_validation = 0\n",
    "    \n",
    "    # Iterate over validation_loader\n",
    "    for i, (images, labels) in enumerate(validation_loader):  \n",
    "        # need to permute so that the images are of size 3x28x28 \n",
    "        # essential to be able to feed images into the model\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Forward, get output\n",
    "        outputs = model(images)\n",
    "\n",
    "        # convert the labels from one hot encoding vectors to integer values\n",
    "        labels = labels.view(-1, 37)\n",
    "        y_true = torch.argmax(labels, 1)\n",
    "        \n",
    "        # calculate the validation loss\n",
    "        loss = criterion(outputs, y_true)\n",
    "\n",
    "        # update the training loss and number of iterations\n",
    "        validation_loss += loss.data[0]\n",
    "        num_iter_validation += 1\n",
    "\n",
    "    print('Validation Loss: {:.4f}'.format(validation_loss/num_iter_validation))\n",
    "    # append all validation_losses over all the epochs\n",
    "    validation_losses.append(validation_loss/num_iter_validation)\n",
    "\n",
    "    num_iter_test = 0\n",
    "    correct = 0\n",
    "    incorrect_dict = dict([(c, 0) for c in characters]) # initializing an empty dictionary of all the characters\n",
    "    \n",
    "    # Iterate over test_loader\n",
    "    for images, labels in test_loader:  \n",
    "\n",
    "        # need to permute so that the images are of size 3x28x28 \n",
    "        # essential to be able to feed images into the model\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "\n",
    "        # convert the labels from one hot encoding vectors into integer values \n",
    "        labels = labels.view(-1, 37)\n",
    "        y_true = torch.argmax(labels, 1)\n",
    "\n",
    "        # find the index of the prediction\n",
    "        y_pred = torch.argmax(outputs, 1).type('torch.FloatTensor')\n",
    "        \n",
    "        # convert to FloatTensor\n",
    "        y_true = y_true.type('torch.FloatTensor')\n",
    "\n",
    "        # find the mean difference of the comparisons\n",
    "        correct += torch.sum(torch.eq(y_true, y_pred).type('torch.FloatTensor'))\n",
    "\n",
    "        # find missclassified characters\n",
    "        # convert to numpy arrays\n",
    "        np_y_true = np.array(y_true)\n",
    "        np_y_pred = np.array(y_pred)        \n",
    "        # which labels were given for the misclassified characters\n",
    "        incorrect_pred = np_y_pred[np_y_pred != np_y_true]\n",
    "        # what the correct labels should be \n",
    "        incorrect_true = np_y_true[np_y_pred != np_y_true]\n",
    "        \n",
    "        # update incorrect_dict\n",
    "        if len(incorrect_true) > 0:\n",
    "            incorrect_dict = get_chars(incorrect_true, incorrect_dict, index2char)\n",
    "        \n",
    "    print('Accuracy on the test set: {:.4f}%'.format(correct/len(test_dataset) * 100))\n",
    "    print('Number of missclassifid characters:', incorrect_dict)\n",
    "    print()\n",
    "\n",
    "# calculate time it took to train the model\n",
    "tf = time.time()\n",
    "print()\n",
    "print(\"time: {} s\" .format(tf-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve function\n",
    "def plot_learning_curve(train_losses, validation_losses):\n",
    "    # plot the training and validation losses\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.plot(train_losses, label=\"training\")\n",
    "    plt.plot(validation_losses, label=\"validation\")\n",
    "    plt.legend(loc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the learning curve\n",
    "plt.title(\"Learning Curve (Loss vs Number of Epochs)\")\n",
    "plot_learning_curve(train_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern 'config_template.ipynb' matched no files\n",
      "This application is used to convert notebook files (*.ipynb) to various other\n",
      "formats.\n",
      "\n",
      "WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
      "\n",
      "Options\n",
      "-------\n",
      "\n",
      "Arguments that take values are actually convenience aliases to full\n",
      "Configurables, whose aliases are listed on the help line. For more information\n",
      "on full configurables, see '--help-all'.\n",
      "\n",
      "--debug\n",
      "    set log level to logging.DEBUG (maximize logging output)\n",
      "--generate-config\n",
      "    generate default config file\n",
      "-y\n",
      "    Answer yes to any questions instead of prompting.\n",
      "--execute\n",
      "    Execute the notebook prior to export.\n",
      "--allow-errors\n",
      "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
      "--stdin\n",
      "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
      "--stdout\n",
      "    Write notebook output to stdout instead of files.\n",
      "--inplace\n",
      "    Run nbconvert in place, overwriting the existing notebook (only \n",
      "    relevant when converting to notebook format)\n",
      "--clear-output\n",
      "    Clear output of current file and save in place, \n",
      "    overwriting the existing notebook.\n",
      "--no-prompt\n",
      "    Exclude input and output prompts from converted document.\n",
      "--log-level=<Enum> (Application.log_level)\n",
      "    Default: 30\n",
      "    Choices: (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL')\n",
      "    Set the log level by value or name.\n",
      "--config=<Unicode> (JupyterApp.config_file)\n",
      "    Default: ''\n",
      "    Full path of a config file.\n",
      "--to=<Unicode> (NbConvertApp.export_format)\n",
      "    Default: 'html'\n",
      "    The export format to be used, either one of the built-in formats, or a\n",
      "    dotted object name that represents the import path for an `Exporter` class\n",
      "--template=<Unicode> (TemplateExporter.template_file)\n",
      "    Default: ''\n",
      "    Name of the template file to use\n",
      "--writer=<DottedObjectName> (NbConvertApp.writer_class)\n",
      "    Default: 'FilesWriter'\n",
      "    Writer class used to write the  results of the conversion\n",
      "--post=<DottedOrNone> (NbConvertApp.postprocessor_class)\n",
      "    Default: ''\n",
      "    PostProcessor class used to write the results of the conversion\n",
      "--output=<Unicode> (NbConvertApp.output_base)\n",
      "    Default: ''\n",
      "    overwrite base name use for output files. can only be used when converting\n",
      "    one notebook at a time.\n",
      "--output-dir=<Unicode> (FilesWriter.build_directory)\n",
      "    Default: ''\n",
      "    Directory to write output(s) to. Defaults to output to the directory of each\n",
      "    notebook. To recover previous default behaviour (outputting to the current\n",
      "    working directory) use . as the flag value.\n",
      "--reveal-prefix=<Unicode> (SlidesExporter.reveal_url_prefix)\n",
      "    Default: ''\n",
      "    The URL prefix for reveal.js. This can be a a relative URL for a local copy\n",
      "    of reveal.js, or point to a CDN.\n",
      "    For speaker notes to work, a local reveal.js prefix must be used.\n",
      "--nbformat=<Enum> (NotebookExporter.nbformat_version)\n",
      "    Default: 4\n",
      "    Choices: [1, 2, 3, 4]\n",
      "    The nbformat version to write. Use this to downgrade notebooks.\n",
      "\n",
      "To see all available configurables, use `--help-all`\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "    The simplest way to use nbconvert is\n",
      "    \n",
      "    > jupyter nbconvert mynotebook.ipynb\n",
      "    \n",
      "    which will convert mynotebook.ipynb to the default format (probably HTML).\n",
      "    \n",
      "    You can specify the export format with `--to`.\n",
      "    Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides']\n",
      "    \n",
      "    > jupyter nbconvert --to latex mynotebook.ipynb\n",
      "    \n",
      "    Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
      "    'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\n",
      "    can specify the flavor of the format used.\n",
      "    \n",
      "    > jupyter nbconvert --to html --template basic mynotebook.ipynb\n",
      "    \n",
      "    You can also pipe the output to stdout, rather than a file\n",
      "    \n",
      "    > jupyter nbconvert mynotebook.ipynb --stdout\n",
      "    \n",
      "    PDF is generated via latex\n",
      "    \n",
      "    > jupyter nbconvert mynotebook.ipynb --to pdf\n",
      "    \n",
      "    You can get (and serve) a Reveal.js-powered slideshow\n",
      "    \n",
      "    > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
      "    \n",
      "    Multiple notebooks can be given at the command line in a couple of \n",
      "    different ways:\n",
      "    \n",
      "    > jupyter nbconvert notebook*.ipynb\n",
      "    > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
      "    \n",
      "    or you can specify the notebooks list in a config file, containing::\n",
      "    \n",
      "        c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
      "    \n",
      "    > jupyter nbconvert --config mycfg.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script config_template.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
